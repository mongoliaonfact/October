---
title: "SIZ October data"
author: "bbaasan"
date: "2022-10-24"
output: word_document
fontsize: 10pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## R Markdown

This is an R Markdown document for October data. 

![Arlington SIZ area and its Fixtures](../images/location.jpg)
# Appearances Dataset
```{r cleaning data, include=FALSE, warning=FALSE}
library(readr)
library(lubridate)
library(tidyverse)

# for Windows
appear14 <- read_csv("../data/appearances 2022-10/appearances_2022-10-14.csv") %>% 
  # for MAC
  #appear14 <- read_csv("/Users/bb/Documents/Arlington/Arlington/data/Oct/appearances 2022-10/appearances_2022-10-14.csv") %>%
  select(ts, user_id, device_id, bird_view) %>% 
  mutate(timestamp = as.POSIXct(ts, tz='EST')) %>% 
  select(ts, timestamp, user_id, device_id, bird_view) %>% 
  mutate(did = str_replace(device_id, '-.*', '')) %>% 
  mutate(yes_no = if_else(grepl('^P', bird_view) == TRUE, "Yes", "No")) %>% 
  select(timestamp, user_id, did, bird_view, yes_no)
```

Let's review whether there are empty or non-assigned geo points for any cells.
```{r review, echo=FALSE, comment=NA}
appear14 %>% 
  select(yes_no) %>% count(yes_no)

```
Data seems to contain no empty cells for geographical location for each row cell.
```{r Counting timestamp, echo=FALSE, comment=NA}
did.table <- as.data.frame(appear14 %>% 
  select(timestamp, did) %>% 
  group_by(did) %>% count(did))

did.table %>% head(2)
```
Let's review the device id (sensors) and its recordings as data frame.

```{r device id table, echo=FALSE}
did.table %>% 
  ggplot(aes(x=did, y=n, fill=did))+
  geom_bar(stat = 'identity')+
  ggtitle('Device ID and its Performance Chart, Oct 14, 2022') +
  xlab('Device ID') + 
  ylab('Number of Objects Detected by the Device id') +
  coord_flip()
```

```{r creating timeseries table, echo=FALSE, comment=NA}
appear14 %>% 
  select(timestamp, user_id, did) %>% 
  group_by(timestamp, did) %>% count(user_id) %>% 
  head(2)
```

```{r creating main time table, echo=FALSE, comment=NA}
timestamp <- seq.POSIXt(as.POSIXct('2022-10-14 00:00:00', tz='EST'), 
           as.POSIXct('2022-10-14 23:59:59', tz='EST'), by = "2 hour")

main_tbl <- as.data.frame(timestamp)
main_tbl %>% head()

# We will look for missing values in the bird view column in the Appearance table.
# Do query on device id and its recordings. Whether there are times when device id does not produce any data
# Two-hours of time interval aggregation (timestamp column) and review the user id: its frequency, count, total number of   user id, sense of tracking individuals 
# Geo locations (bird view) into visible demonstration of area of the recordings
```
Let's review the how 
```{r echo=FALSE, comment=NA}
# FUNC 4: remove parenthesis from POINT column and split the column into
rmove_parenthesis <- function(df){
        df$bird_view <- gsub('[()]', '', df$bird_view)
        df %>% 
                separate(bird_view, c('Point', 'Y', 'X'), sep = ' ')}
```


```{r echo=FALSE, comment=NA}
geo_tbl <- rmove_parenthesis(appear14)%>% 
  mutate(userid = str_replace(user_id, '-.*', '')) %>% 
  select(timestamp, Y, X, did, userid)

geo_tbl %>% head()
```

```{r echo=FALSE, comment=NA}
geo_tbl %>% 
  mutate(twohours = cut(timestamp, breaks = '2 hours')) %>%
  select(twohours, Y, X, did, userid) %>% 
  group_by(twohours, did) %>% count(userid) %>% 
  head()

```
## Steps took to analyze the geo points include:
### 1. Allocate geo points of the each user id
![Geo Points](../images/appear14_geopoints.jpg)

### 2. Draw a polygon that covers SIZ area.
![SIZ area](../images/appear14_geopoints2.jpg)

### 3. Clip the geo points within the polygon of the SIZ area

![Clipped Geo Points within the SIZ area](../images/appear14_clipped.jpg)

### 4. Color the geo points based on device id
![Geo Points colored by Device ID](../images/appear14_colored_bydid.jpg){width=50%, height=50%}
# Lines Crossed Dataset
Review data set and its structure, column names.
```{r echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

crossed14 <- read_csv('../data/lines_crossed 2022-10/lines_crossed_2022-10-14.csv') %>% 
  mutate(timestamp = as.POSIXct(ts, tz='EST')) %>% 
  mutate(did = str_replace(device_id, '-.*', '')) 

crossed14 %>% 
  str()
```

```{r echo=FALSE, comment=NA, message=FALSE}

crossed_count <- crossed14 %>%  
  rename(too = count) %>% 
  select(timestamp, did, device_id, label, too) %>%
  group_by(did, label) %>% summarize(total=sum(too)) %>% 
  add_column(fixture = c(5,1,7,2))

crossed_count
```
```{r echo=FALSE, comment=NA}
crossed14_did <- crossed14 %>% 
  select(timestamp, did, count) %>% 
  mutate(twohours = cut(timestamp, breaks = '2 hours')) %>% 
  select(twohours, did, count) %>% 
  group_by(twohours, did) %>% summarise(total = sum(count)) %>% 
  pivot_wider(twohours, names_from = did, values_from = total)

crossed14_did %>% head()

```

```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE}
appear_pivot <- geo_tbl %>% 
  mutate(twohours = cut(timestamp, breaks = '2 hours')) %>%
  select(twohours, Y, X, did, userid) %>% 
  group_by(twohours, did) %>% count(userid) %>%
  group_by(twohours, did) %>% summarise(total = sum(n)) %>%  # this sums each user id by device id
  pivot_wider(twohours, names_from = did, values_from = total) %>% 
  mutate(timestamp = as.character(twohours))

appear_pivot %>% dim()

```



```{r echo=FALSE, comment=NA,warning=FALSE, message=FALSE}

appear_crossed_df <- main_tbl %>% 
  mutate(twohours = as.factor(timestamp)) %>% 
  right_join(appear_pivot, by="twohours") %>% 
  right_join(crossed14_did, by="twohours") %>% 
  select(-c(twohours, timestamp.y)) %>% 
  replace(is.na(.), 0)

appear_crossed_df %>% head()
```
```{r echo=FALSE, comment=NA, warning=FALSE, message=FALSE}

appear_crossed_df %>% 
  mutate(appear_rowsum = rowSums(appear_crossed_df[,2:14])) %>% 
  mutate(crossed_rowsum = rowSums(appear_crossed_df[,15:18])) %>% 
  select(timestamp.x, appear_rowsum, crossed_rowsum) %>% 
  pivot_longer(cols = - c(timestamp.x), 
               names_to = 'dataset', 
               values_to = 'ppl_count') %>% 
  ggplot(aes(x=timestamp.x, y=ppl_count, color=dataset))+
  geom_line(size=1)+
  geom_point()+
  ggtitle('Appearance and Lines Crossed Dataset Oct 14')+
  xlab('Month/Day Time')
```

```{r echo=FALSE}
appear_crossed_df %>% 
  mutate(appear_rowsum = rowSums(appear_crossed_df[,2:14])) %>% 
  mutate(crossed_rowsum = rowSums(appear_crossed_df[,15:18])) %>% 
  select(timestamp.x, appear_rowsum, crossed_rowsum) %>% 
  pivot_longer(cols = - c(timestamp.x), 
               names_to = 'dataset', 
               values_to = 'ppl_count') %>% 
  ggplot(aes(x=timestamp.x, y= log(ppl_count), color=dataset))+
  geom_line(size=1)+
  geom_point()+
  ggtitle('Appearance and Lines Crossed Dataset Oct 14, Log Scale')+
  xlab('Month/Day Time') #+
  #ggsave('../figures/Appearance_LinesCrossed_Linegraph.png')

```
```{r echo=FALSE, message=FALSE, comment=NA}
# this is a function that reads csv file in the path and does conversion
# and returns converted timestamp, userid, device id (did) and bird_view 
# geographicall location.

ts_uid_did_bv <- function(csv_file_path){
  read_csv(csv_file_path) %>% 
  # for MAC
  #appear14 <- read_csv("/Users/bb/Documents/Arlington/Arlington/data/Oct/appearances 2022-10/appearances_2022-10-14.csv") %>%
  select(ts, user_id, device_id, bird_view) %>% 
  mutate(timestamp = as.POSIXct(ts, tz='EST')) %>% 
  mutate(userid = str_replace(user_id, '-.*', '')) %>% 
  mutate(did = str_replace(device_id, '-.*', '')) %>% 
  select(timestamp, userid, did, bird_view)
  }
```

```{r echo=FALSE, message=FALSE, comment=NA}
# 
df <- ts_uid_did_bv('../data/appearances 2022-10/appearances_2022-10-15.csv')
df <- rmove_parenthesis(df) %>% 
                    select(timestamp, userid, did, Y, X)

```

## save the file in csv format for Qgis upload
```{r echo=FALSE, message=FALSE, comment=NA}
# write.csv(df, '../data/appear15_geolocation.csv', row.names = FALSE)

```

Appearance October 15 data seems to follow the same pattern of allocating geo
points beyond the SIZ area. 
![Appearance dataset October 15, 2022](../images/appear15_geopoints.jpg)
```{r echo=FALSE, message=FALSE, comment=NA}
df16 <- ts_uid_did_bv('../data/appearances 2022-10/appearances_2022-10-16.csv')
df16 <- rmove_parenthesis(df16) %>% 
                    select(timestamp, userid, did, Y, X)
```

```{r echo=FALSE, message=FALSE, comment=NA}
#write.csv(df16, '../data/appear16_geolocation.csv', row.names = FALSE)

```
As well as Appearance October 16 data seems to follow the same pattern of allocating geo
points beyond the SIZ area. 
![Appearance dataset October 16, 2022](../images/appear16_geopoints.jpg)